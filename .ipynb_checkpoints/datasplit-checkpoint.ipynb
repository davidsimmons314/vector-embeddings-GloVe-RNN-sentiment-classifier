{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29404c90-71ad-4fd7-8305-aa9fc02df962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to randomly split data into 70% train set, 15% dev set, and 15% test set\n",
    "# saves to folders '/review_polarity/txt_sentoken/train/pos', '/review_polarity/txt_sentoken/train/neg'\n",
    "# '/review_polarity/txt_sentoken/dev/pos', '/review_polarity/txt_sentoken/dev/neg'\n",
    "# and  '/review_polarity/txt_sentoken/test/pos', '/review_polarity/txt_sentoken/test/neg'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "cwd = os.getcwd()\n",
    "dir = cwd + '/review_polarity/txt_sentoken'\n",
    "\n",
    "# array of strings for filenames and respective sentiment of total dataset\n",
    "total_dataset_filenames = np.empty(0, dtype = str)\n",
    "total_dataset_sentiment = np.empty(0, dtype = str)\n",
    "# add all positive filenames\n",
    "pos_dir = dir + '/pos'\n",
    "for filename in os.listdir(pos_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        total_dataset_filenames = np.append(total_dataset_filenames, filename)\n",
    "        total_dataset_sentiment = np.append(total_dataset_sentiment, 'pos')\n",
    "\n",
    "# add all negative filenames\n",
    "neg_dir = dir + '/neg'\n",
    "for filename in os.listdir(neg_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        total_dataset_filenames = np.append(total_dataset_filenames,filename)\n",
    "        total_dataset_sentiment = np.append(total_dataset_sentiment, 'neg')\n",
    "\n",
    "# compute sizes\n",
    "dataset_size = len(total_dataset_filenames)\n",
    "train_size = int(0.70 * dataset_size)\n",
    "dev_size = int(0.15 * dataset_size)\n",
    "test_size = dataset_size - train_size - dev_size\n",
    "\n",
    "# generate random indices and split among train_indices and test_indices\n",
    "indices = np.arange(0, dataset_size)\n",
    "random_indices = np.random.permutation(indices)\n",
    "train_indices = random_indices[np.arange(0, train_size)]\n",
    "dev_indices = random_indices[np.arange(train_size, train_size + dev_size)]\n",
    "test_indices = random_indices[np.arange(train_size + dev_size, dataset_size)]\n",
    "\n",
    "dir = cwd + '/review_polarity/txt_sentoken'\n",
    "\n",
    "# first 70% of shuffled files are saved as train data\n",
    "os.mkdir(dir + '/train')\n",
    "os.mkdir(dir + '/train/pos')\n",
    "os.mkdir(dir + '/train/neg')\n",
    "for i in range(train_size):\n",
    "    filename = total_dataset_filenames[random_indices[i]]\n",
    "    sentiment = total_dataset_sentiment[random_indices[i]]\n",
    "\n",
    "    src_path = dir + '/' + sentiment + '/' + filename\n",
    "    dst_path = dir + '/train/' + sentiment + '/' + filename\n",
    "\n",
    "    src_file = open(src_path, 'r')\n",
    "    dst_file = open(dst_path, 'w')\n",
    "\n",
    "    dst_file.write(src_file.read())\n",
    "\n",
    "    src_file.close()\n",
    "    dst_file.close()\n",
    "    \n",
    "# last 15% of shuffled files are saved as dev data\n",
    "os.mkdir(dir + '/dev')\n",
    "os.mkdir(dir + '/dev/pos')\n",
    "os.mkdir(dir + '/dev/neg')\n",
    "for i in range(train_size, train_size + dev_size):\n",
    "    filename = total_dataset_filenames[random_indices[i]]\n",
    "    sentiment = total_dataset_sentiment[random_indices[i]]\n",
    "\n",
    "    src_path = dir + '/' + sentiment + '/' + filename\n",
    "    dst_path = dir + '/dev/' + sentiment + '/' + filename\n",
    "\n",
    "    src_file = open(src_path, 'r')\n",
    "    dst_file = open(dst_path, 'w')\n",
    "\n",
    "    dst_file.write(src_file.read())\n",
    "\n",
    "    src_file.close()\n",
    "    dst_file.close()\n",
    "\n",
    "# last 15% of shuffled files are saved as test data\n",
    "os.mkdir(dir + '/test')\n",
    "os.mkdir(dir + '/test/pos')\n",
    "os.mkdir(dir + '/test/neg')\n",
    "for i in range(train_size + dev_size, dataset_size):\n",
    "    filename = total_dataset_filenames[random_indices[i]]\n",
    "    sentiment = total_dataset_sentiment[random_indices[i]]\n",
    "\n",
    "    src_path = dir + '/' + sentiment + '/' + filename\n",
    "    dst_path = dir + '/test/' + sentiment + '/' + filename\n",
    "\n",
    "    src_file = open(src_path, 'r')\n",
    "    dst_file = open(dst_path, 'w')\n",
    "\n",
    "    dst_file.write(src_file.read())\n",
    "\n",
    "    src_file.close()\n",
    "    dst_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f7b619-c7e2-438e-8a00-f246c658a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b66b394-0248-4f2a-b91d-33f3675952ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
